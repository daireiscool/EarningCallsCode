{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\daire\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\daire\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\daire\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found API <class 'GLTR.api.LM'> with name gpt-2-small\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 400)\n",
    "\n",
    "from DetectGPT.model import GPT2PPLV2 as GPT2PPL\n",
    "from GLTR.api import LM as GLTR\n",
    "from transformers import OpenAIGPTLMHeadModel, OpenAIGPTTokenizer, pipeline\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 indicated AI produced, 0 indicates human produced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJSON(location):\n",
    "    with open(location, encoding = \"utf-8\") as outfile:\n",
    "        data = json.load(outfile)\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRobertaScore(text):\n",
    "    \"\"\"\n",
    "    https://huggingface.co/roberta-base-openai-detector\n",
    "    \"\"\"\n",
    "    model = pipeline(\"text-classification\", model=\"roberta-base-openai-detector\")\n",
    "    vals = model(text, top_k=3)\n",
    "    flag = sorted(vals, key = lambda x: x[\"score\"])[-1][\"label\"]\n",
    "    flag = 1 if flag == \"Fake\" else 0\n",
    "    \n",
    "    return {**{f\"roberta_score_{j['label']}\": j[\"score\"] for j in vals}, **{\"roberta_Label\": flag}}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRobertaLargeScore(text):\n",
    "    \"\"\"\n",
    "    https://huggingface.co/roberta-large-openai-detector\n",
    "    \"\"\"\n",
    "    model = pipeline(\"text-classification\", model=\"roberta-large-openai-detector\")\n",
    "    vals = model(text, top_k=3)\n",
    "    flag = sorted(vals, key = lambda x: x[\"score\"])[-1][\"label\"]\n",
    "    flag = 1 if flag == \"LABEL_0\" else 0\n",
    "    \n",
    "    d = {\"LABEL_1\":\"0\", \"LABEL_0\":1}\n",
    "    \n",
    "    return {**{f\"roberta_large_score_{d[j['label']]}\": j[\"score\"] for j in vals}, **{\"roberta_large_Label\": flag}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDetectGPTScore(text):\n",
    "    \"\"\"\n",
    "    https://www.arxiv-vanity.com/papers/2301.11305/\n",
    "    Slow though...\n",
    "    \"\"\"\n",
    "    model = GPT2PPL()\n",
    "    vals = model(text, len(text), \"v1.1\")\n",
    "    flag = 1 - vals[0]\n",
    "    \n",
    "    return {\"gpt_detect_mean_score\": vals[2], \n",
    "            \"gpt_detect_mean_probability\": vals[3], \n",
    "            \"gpt_detect_Label\": flag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGPTZeroScore(text):\n",
    "    \"\"\"\n",
    "    https://gptzero.me/\n",
    "    \"\"\"\n",
    "    model = GPT2PPL()\n",
    "    vals = model(text, None, \"v1\")\n",
    "    flag = 1 - vals[0][\"label\"]\n",
    "    \n",
    "    return {\"gpt_zero_Perplexity\": vals[0][\"Perplexity\"], \n",
    "            \"gpt_zero_Burtiness\": vals[0][\"Burstiness\"], \n",
    "            \"gpt_zero_Label\": flag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGLTRScore(text, threshold = 0.7):\n",
    "    \"\"\"\n",
    "    http://gltr.io/\n",
    "    \"\"\"\n",
    "    gltr = GLTR()\n",
    "    def f(x):\n",
    "        return int(np.where(\n",
    "            x<10, 0, np.where(x<100, 1, np.where(x<1000, 2, 3))))\n",
    "\n",
    "    def p(x, vals):\n",
    "        return sum(np.array(vals) == x)/len(vals)\n",
    "\n",
    "    valsALL = gltr.check_probabilities(text)\n",
    "    vals = [f(i[0]) for i in valsALL[\"real_topk\"]]\n",
    "    \n",
    "    flag = 1 if p(0, vals) > threshold else 0 \n",
    "    \n",
    "    return {\"gltr_0\": p(0, vals), \n",
    "            \"gltr_1\": p(1, vals),\n",
    "            \"gltr_2\": p(2, vals),\n",
    "            \"gltr_3\": p(3, vals),\n",
    "            \"gltr_Label\": flag}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# roberta_dict = getRobertaScore(textSub)\n",
    "# roberta_large_dict = getRobertaLargeScore(textSub)\n",
    "# gpt_zero_dict = getGPTZeroScore(textSub)\n",
    "# gpt_detect_dict = getDetectGPTScore(textSub)\n",
    "# gltr_dict = getGLTRScore(textSub)\n",
    "\n",
    "# {**roberta_dict, **gpt_zero_dict, **gpt_detect_dict, **roberta_large_dict, **gltr_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isAIGenerated(text, chunksize = 300, step_size = 300):\n",
    "    \"\"\"\n",
    "    Detect if a function is AI generated or not.\n",
    "    This will return several scores, which are\n",
    "        * GPTZero - https://gptzero.me/\n",
    "        * Roberta - https://huggingface.co/roberta-base-openai-detector\n",
    "        * Roberta Large - https://huggingface.co/roberta-large-openai-detector\n",
    "        * Potentially GLTR in future... - http://gltr.io/dist/index.html\n",
    "    \n",
    "    ::param text: (str)\n",
    "    ::param chunksize: (int)\n",
    "    ::param step_size: (int)\n",
    "    \n",
    "    ::return: (dict[str: float])\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame()\n",
    "    savedText = []\n",
    "    textSplit = text.split()\n",
    "    try:\n",
    "        for i in range(np.max(1, len(textSplit)//step_size)):\n",
    "            textSub = \" \".join(textSplit[step_size*i:(step_size*i) + chunksize])\n",
    "\n",
    "            roberta_dict = getRobertaScore(textSub)\n",
    "            roberta_large_dict = getRobertaLargeScore(textSub)\n",
    "            gpt_zero_dict = getGPTZeroScore(textSub)\n",
    "            gpt_detect_dict = {}#getDetectGPTScore(textSub)\n",
    "            gltr_dict = getGLTRScore(textSub)\n",
    "\n",
    "            data = data.append({**roberta_dict, **gpt_zero_dict, **gpt_detect_dict, **roberta_large_dict, **gltr_dict}, ignore_index=True)\n",
    "            savedText += [textSub]\n",
    "        data[\"Text\"] = savedText\n",
    "        return data\n",
    "    except:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# textSub = \"\"\"\n",
    "# In the year 2050, artificial intelligence has transformed every aspect of human life. From self-driving cars to intelligent personal assistants, AI has become an indispensable part of our daily routine. People now live in smart homes where AI-powered systems control the temperature, lighting, and security with perfect precision.\n",
    "# In the field of medicine, AI has revolutionized healthcare. Advanced algorithms analyze vast amounts of medical data to diagnose diseases at an early stage and recommend personalized treatments. Surgeries are performed with the assistance of surgical robots, ensuring unparalleled precision and minimizing human error.\n",
    "# Education has also undergone a significant transformation. AI tutors provide personalized learning experiences, adapting to each student's unique needs and learning style. Virtual reality simulations create immersive environments for students to explore various subjects, making education more engaging and interactive than ever before.\n",
    "# AI has even extended its reach to the creative realm. AI-generated artwork, music, and literature have gained recognition and appreciation among audiences worldwide. Machines have become proficient in composing symphonies, painting masterpieces, and crafting compelling stories that evoke emotions and captivate the imagination.\n",
    "# While AI has brought numerous benefits, it has also raised ethical concerns. The increasing reliance on AI has led to discussions about job displacement and the potential loss of human touch in various industries. Striking the right balance between automation and human involvement remains a critical challenge for society.\n",
    "# As AI continues to advance, the possibilities seem limitless. The future holds promises of further breakthroughs in areas such as quantum computing, deep learning, and neural interfaces. It is an exciting time to witness the ever-evolving landscape of artificial intelligence and its impact on shaping our future.\n",
    "# \"\"\"\n",
    "\n",
    "# print(\"RoBERTa\")\n",
    "# st = time.time()\n",
    "# roberta_dict = getRobertaScore(textSub)\n",
    "# print(f\"Took {round(time.time() - st, 2)} seconds\")\n",
    "# print(\"RoBERTa Large\")\n",
    "# st = time.time()\n",
    "# roberta_large_dict = getRobertaLargeScore(textSub)\n",
    "# print(f\"Took {round(time.time() - st, 2)} seconds\")\n",
    "# print(\"GPTZero\")\n",
    "# st = time.time()\n",
    "# gpt_zero_dict = getGPTZeroScore(textSub)\n",
    "# print(f\"Took {round(time.time() - st, 2)} seconds\")\n",
    "# print(\"DetectGPT\")\n",
    "# st = time.time()\n",
    "# gpt_detect_dict = getDetectGPTScore(textSub)\n",
    "# print(f\"Took {round(time.time() - st, 2)} seconds\")\n",
    "# print(\"GLTR\")\n",
    "# st = time.time()\n",
    "# gltr_dict = getGLTRScore(textSub)\n",
    "# print(f\"Took {round(time.time() - st, 2)} seconds\")\n",
    "\n",
    "# {**roberta_dict, **roberta_large_dict, **gpt_zero_dict, **gpt_detect_dict, **gltr_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Human    306\n",
       "GPT4     236\n",
       "GPT3     207\n",
       "Name: model, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = readJSON(\"validation.json\")\n",
    "validation[\"id\"] = range(len(validation))\n",
    "validation[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 5432)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[\"length\"] = validation[\"text\"].apply(lambda x: len(x))\n",
    "validation[\"length\"].min(), validation[\"length\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of datframe: 749\n",
      "0/749 --- Text Size: 84 --- Took 14.42 seconds.\n",
      "1/749 --- Text Size: 83 --- Took 13.05 seconds.\n",
      "2/749 --- Text Size: 124 --- Took 13.83 seconds.\n",
      "3/749 --- Text Size: 83 --- Took 12.97 seconds.\n",
      "4/749 --- Text Size: 84 --- Took 12.67 seconds.\n",
      "5/749 --- Text Size: 90 --- Took 13.06 seconds.\n",
      "6/749 --- Text Size: 134 --- Took 13.82 seconds.\n",
      "7/749 --- Text Size: 98 --- Took 12.95 seconds.\n",
      "8/749 --- Text Size: 94 --- Took 12.87 seconds.\n",
      "9/749 --- Text Size: 92 --- Took 12.71 seconds.\n",
      "10/749 --- Text Size: 83 --- Took 12.63 seconds.\n",
      "11/749 --- Text Size: 99 --- Took 12.96 seconds.\n",
      "12/749 --- Text Size: 78 --- Took 12.57 seconds.\n",
      "13/749 --- Text Size: 81 --- Took 12.68 seconds.\n",
      "14/749 --- Text Size: 73 --- Took 12.67 seconds.\n",
      "15/749 --- Text Size: 91 --- Took 12.9 seconds.\n",
      "16/749 --- Text Size: 103 --- Took 13.06 seconds.\n",
      "17/749 --- Text Size: 75 --- Took 12.6 seconds.\n",
      "18/749 --- Text Size: 71 --- Took 12.46 seconds.\n",
      "19/749 --- Text Size: 91 --- Took 12.76 seconds.\n",
      "20/749 --- Text Size: 80 --- Took 12.65 seconds.\n",
      "21/749 --- Text Size: 104 --- Took 13.11 seconds.\n",
      "22/749 --- Text Size: 72 --- Took 12.6 seconds.\n",
      "23/749 --- Text Size: 87 --- Took 12.91 seconds.\n",
      "24/749 --- Text Size: 83 --- Took 12.63 seconds.\n",
      "25/749 --- Text Size: 80 --- Took 12.91 seconds.\n",
      "26/749 --- Text Size: 92 --- Took 12.89 seconds.\n",
      "27/749 --- Text Size: 98 --- Took 12.93 seconds.\n",
      "28/749 --- Text Size: 104 --- Took 13.08 seconds.\n",
      "29/749 --- Text Size: 107 --- Took 13.46 seconds.\n",
      "30/749 --- Text Size: 90 --- Took 12.91 seconds.\n",
      "31/749 --- Text Size: 87 --- Took 12.62 seconds.\n",
      "32/749 --- Text Size: 81 --- Took 12.45 seconds.\n",
      "33/749 --- Text Size: 102 --- Took 13.32 seconds.\n",
      "34/749 --- Text Size: 80 --- Took 12.84 seconds.\n",
      "35/749 --- Text Size: 95 --- Took 13.19 seconds.\n",
      "36/749 --- Text Size: 87 --- Took 12.8 seconds.\n",
      "37/749 --- Text Size: 73 --- Took 12.68 seconds.\n",
      "38/749 --- Text Size: 87 --- Took 12.93 seconds.\n",
      "39/749 --- Text Size: 121 --- Took 13.96 seconds.\n",
      "40/749 --- Text Size: 134 --- Took 13.52 seconds.\n",
      "41/749 --- Text Size: 82 --- Took 12.92 seconds.\n",
      "42/749 --- Text Size: 86 --- Took 12.67 seconds.\n",
      "43/749 --- Text Size: 110 --- Took 12.93 seconds.\n",
      "44/749 --- Text Size: 98 --- Took 12.83 seconds.\n",
      "45/749 --- Text Size: 80 --- Took 12.89 seconds.\n",
      "46/749 --- Text Size: 115 --- Took 13.64 seconds.\n",
      "47/749 --- Text Size: 103 --- Took 13.34 seconds.\n",
      "48/749 --- Text Size: 94 --- Took 13.08 seconds.\n",
      "49/749 --- Text Size: 115 --- Took 13.73 seconds.\n",
      "50/749 --- Text Size: 89 --- Took 12.83 seconds.\n",
      "51/749 --- Text Size: 65 --- Took 12.41 seconds.\n",
      "52/749 --- Text Size: 108 --- Took 13.25 seconds.\n",
      "53/749 --- Text Size: 94 --- Took 12.94 seconds.\n",
      "54/749 --- Text Size: 86 --- Took 12.9 seconds.\n",
      "55/749 --- Text Size: 66 --- Took 12.19 seconds.\n",
      "56/749 --- Text Size: 115 --- Took 13.26 seconds.\n",
      "57/749 --- Text Size: 89 --- Took 12.96 seconds.\n",
      "58/749 --- Text Size: 109 --- Took 13.1 seconds.\n",
      "59/749 --- Text Size: 83 --- Took 12.81 seconds.\n",
      "60/749 --- Text Size: 92 --- Took 12.91 seconds.\n",
      "61/749 --- Text Size: 79 --- Took 13.1 seconds.\n",
      "62/749 --- Text Size: 73 --- Took 12.44 seconds.\n",
      "63/749 --- Text Size: 89 --- Took 12.7 seconds.\n",
      "64/749 --- Text Size: 56 --- Took 12.1 seconds.\n",
      "65/749 --- Text Size: 69 --- Took 12.28 seconds.\n",
      "66/749 --- Text Size: 85 --- Took 12.91 seconds.\n",
      "67/749 --- Text Size: 75 --- Took 12.24 seconds.\n",
      "68/749 --- Text Size: 92 --- Took 12.64 seconds.\n",
      "69/749 --- Text Size: 107 --- Took 13.1 seconds.\n",
      "70/749 --- Text Size: 82 --- Took 12.76 seconds.\n",
      "71/749 --- Text Size: 95 --- Took 13.09 seconds.\n",
      "72/749 --- Text Size: 84 --- Took 12.64 seconds.\n",
      "73/749 --- Text Size: 96 --- Took 13.02 seconds.\n",
      "74/749 --- Text Size: 81 --- Took 12.52 seconds.\n",
      "75/749 --- Text Size: 90 --- Took 12.73 seconds.\n",
      "76/749 --- Text Size: 90 --- Took 12.6 seconds.\n",
      "77/749 --- Text Size: 94 --- Took 12.87 seconds.\n",
      "78/749 --- Text Size: 73 --- Took 12.67 seconds.\n",
      "79/749 --- Text Size: 119 --- Took 13.37 seconds.\n",
      "80/749 --- Text Size: 88 --- Took 12.59 seconds.\n",
      "81/749 --- Text Size: 96 --- Took 13.12 seconds.\n",
      "82/749 --- Text Size: 102 --- Took 12.86 seconds.\n",
      "83/749 --- Text Size: 89 --- Took 12.87 seconds.\n",
      "84/749 --- Text Size: 84 --- Took 12.65 seconds.\n",
      "85/749 --- Text Size: 99 --- Took 13.11 seconds.\n",
      "86/749 --- Text Size: 83 --- Took 12.48 seconds.\n",
      "87/749 --- Text Size: 80 --- Took 12.46 seconds.\n",
      "88/749 --- Text Size: 117 --- Took 13.16 seconds.\n",
      "89/749 --- Text Size: 94 --- Took 12.9 seconds.\n",
      "90/749 --- Text Size: 97 --- Took 12.82 seconds.\n",
      "91/749 --- Text Size: 139 --- Took 14.3 seconds.\n",
      "92/749 --- Text Size: 119 --- Took 13.11 seconds.\n",
      "93/749 --- Text Size: 220 --- Took 15.36 seconds.\n",
      "94/749 --- Text Size: 148 --- Took 14.15 seconds.\n",
      "95/749 --- Text Size: 214 --- Took 15.68 seconds.\n",
      "96/749 --- Text Size: 133 --- Took 14.05 seconds.\n",
      "97/749 --- Text Size: 159 --- Took 14.3 seconds.\n",
      "98/749 --- Text Size: 197 --- Took 15.67 seconds.\n",
      "99/749 --- Text Size: 169 --- Took 15.29 seconds.\n",
      "100/749 --- Text Size: 128 --- Took 13.23 seconds.\n",
      "101/749 --- Text Size: 135 --- Took 14.44 seconds.\n",
      "102/749 --- Text Size: 213 --- Took 15.67 seconds.\n",
      "103/749 --- Text Size: 96 --- Took 12.71 seconds.\n",
      "104/749 --- Text Size: 193 --- Took 15.65 seconds.\n",
      "105/749 --- Text Size: 171 --- Took 16.1 seconds.\n",
      "106/749 --- Text Size: 115 --- Took 13.77 seconds.\n",
      "107/749 --- Text Size: 82 --- Took 12.63 seconds.\n",
      "108/749 --- Text Size: 218 --- Took 15.85 seconds.\n",
      "109/749 --- Text Size: 227 --- Took 16.14 seconds.\n",
      "110/749 --- Text Size: 159 --- Took 15.18 seconds.\n",
      "111/749 --- Text Size: 115 --- Took 13.49 seconds.\n",
      "112/749 --- Text Size: 227 --- Took 15.88 seconds.\n",
      "113/749 --- Text Size: 276 --- Took 16.68 seconds.\n",
      "114/749 --- Text Size: 212 --- Took 15.31 seconds.\n",
      "115/749 --- Text Size: 112 --- Took 13.73 seconds.\n",
      "116/749 --- Text Size: 203 --- Took 16.1 seconds.\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-208e0c54951c>\u001b[0m in \u001b[0;36misAIGenerated\u001b[1;34m(text, chunksize, step_size)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mtextSplit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextSplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mtextSub\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtextSplit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2789\u001b[0m     \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2790\u001b[0m     \"\"\"\n\u001b[1;32m-> 2791\u001b[1;33m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0m\u001b[0;32m   2792\u001b[0m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0;32m   2793\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "allData, metaData = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "print(f\"Length of datframe: {len(validation)}\")\n",
    "for num, i in enumerate(validation.iterrows()):\n",
    "    st = time.time()\n",
    "    text = i[1][\"text\"]\n",
    "    id_ = i[1][\"id\"]\n",
    "    model = i[1][\"model\"]\n",
    "\n",
    "    values = isAIGenerated(text)\n",
    "    metrics = values.describe().reset_index()\n",
    "    \n",
    "    values[\"id\"] = id_\n",
    "    metrics[\"id\"] = id_\n",
    "\n",
    "    values[\"model\"] = id_\n",
    "    metrics[\"model\"] = id_\n",
    "\n",
    "    allData = pd.concat([allData, metrics])\n",
    "    metaData = pd.concat([metaData, values])\n",
    "    print(f\"{num}/{len(validation)} --- Text Size: {len(text.split())} --- Took {round(time.time() - st, 2)} seconds.\")\n",
    "\n",
    "allData.to_csv(\"MetricsValidation.csv\")\n",
    "metaData.to_excel(\"MetaValidation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metaData = pd.read_excel(\"MetaValidation.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = validation.merge(metaData.groupby(\"id\").mean().reset_index(), on = \"id\")[[\"kind\", \"gpt_zero_Label\", \"gltr_Label\", \"roberta_Label\", \"roberta_large_Label\"]]\n",
    "d[\"Label\"] = d[\"kind\"].map({\"Human-Written\":0}).fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>gpt_zero_Label</th>\n",
       "      <th>gltr_Label</th>\n",
       "      <th>roberta_Label</th>\n",
       "      <th>roberta_large_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label  gpt_zero_Label  gltr_Label  roberta_Label  roberta_large_Label\n",
       "0      1.0             1.0         0.0            0.0                  0.0\n",
       "1      1.0             0.0         0.0            0.0                  0.0\n",
       "2      1.0             1.0         1.0            0.0                  0.0\n",
       "3      1.0             1.0         1.0            0.0                  0.0\n",
       "4      1.0             1.0         0.0            0.0                  0.0\n",
       "..     ...             ...         ...            ...                  ...\n",
       "112    0.0             1.0         0.0            0.0                  0.0\n",
       "113    0.0             1.0         0.0            0.0                  0.0\n",
       "114    0.0             0.0         0.0            0.0                  0.0\n",
       "115    0.0             0.0         0.0            0.0                  0.0\n",
       "116    0.0             0.0         0.0            0.0                  0.0\n",
       "\n",
       "[117 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[[\"Label\", \"gpt_zero_Label\", \"gltr_Label\", \"roberta_Label\", \"roberta_large_Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gpt_zero_Label</th>\n",
       "      <th>gltr_Label</th>\n",
       "      <th>roberta_Label</th>\n",
       "      <th>roberta_large_Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gpt_zero_Label  gltr_Label  roberta_Label  roberta_large_Label\n",
       "Label                                                                \n",
       "0.0          0.307692    0.076923       0.000000             0.000000\n",
       "1.0          0.813187    0.307692       0.043956             0.010989"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.groupby(\"Label\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt_zero_Label\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.69      0.59        26\n",
      "        True       0.90      0.81      0.86        91\n",
      "\n",
      "    accuracy                           0.79       117\n",
      "   macro avg       0.71      0.75      0.72       117\n",
      "weighted avg       0.82      0.79      0.80       117\n",
      "\n",
      "\n",
      "gltr_Label\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.28      0.92      0.42        26\n",
      "        True       0.93      0.31      0.46        91\n",
      "\n",
      "    accuracy                           0.44       117\n",
      "   macro avg       0.60      0.62      0.44       117\n",
      "weighted avg       0.79      0.44      0.45       117\n",
      "\n",
      "\n",
      "roberta_Label\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.23      1.00      0.37        26\n",
      "        True       1.00      0.04      0.08        91\n",
      "\n",
      "    accuracy                           0.26       117\n",
      "   macro avg       0.62      0.52      0.23       117\n",
      "weighted avg       0.83      0.26      0.15       117\n",
      "\n",
      "\n",
      "roberta_large_Label\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.22      1.00      0.37        26\n",
      "        True       1.00      0.01      0.02        91\n",
      "\n",
      "    accuracy                           0.23       117\n",
      "   macro avg       0.61      0.51      0.19       117\n",
      "weighted avg       0.83      0.23      0.10       117\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for LABEL in [\"gpt_zero_Label\", \"gltr_Label\",\"roberta_Label\",\"roberta_large_Label\"]:\n",
    "    print(LABEL)\n",
    "    print(classification_report(d[\"Label\"].astype(bool).values, d[LABEL].astype(bool).values))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
